{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfOgI8GHWIG1"
   },
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogh-USrxc6IR"
   },
   "source": [
    "Perpceptron Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "k7fipBPaA_H-"
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "  # Initializing weights,learning rate aand epochs\n",
    "  def __init__(self,eta,epochs):\n",
    "    # Random Weight Assignment\n",
    "    self.weights = np.random.randn(3) * 1e-4\n",
    "    print(\"Initial weights\",self.weights)\n",
    "    self.eta = eta\n",
    "    self.epochs = epochs\n",
    "\n",
    "\n",
    "# Defining the Activation Function - using the step function\n",
    "  def activationFunction(self,inputs,weights):\n",
    "    # Multiplying weights and the input values \n",
    "    z = np.dot(inputs,weights)\n",
    "    return np.where(z>0,1,0)\n",
    "\n",
    "# Defining the Fit Method\n",
    "  def fit(self,X,y):\n",
    "    self.X=X\n",
    "    self.y=y\n",
    "    # Adding bias to the input values \n",
    "    X_with_bias = np.c_[self.X,-np.ones((len(self.X),1))]\n",
    "    print(\"X with Bias \",X_with_bias)\n",
    "\n",
    "    # Forward  & backward Propogation\n",
    "    for epoch in range(self.epochs):\n",
    "        \n",
    "        print(\"====================\")\n",
    "        print(\"for epoch\",epoch)\n",
    "        print(\"====================\")\n",
    "\n",
    "        y_hat = self.activationFunction(X_with_bias,self.weights)\n",
    "        print(\"predicted values\",y_hat)\n",
    "        self.error = self.y - y_hat\n",
    "        # Early Stopping (basic implementation)\n",
    "        #- Need to compare with previous error value in reality)\n",
    "        if np.sum(self.error)==0:\n",
    "            break\n",
    "        # Weights updation \n",
    "        self.weights = self.weights + self.eta* np.dot(X_with_bias.T,self.error)\n",
    "        print(\"Updated weights after epoch\",self.epochs,self.weights)\n",
    "\n",
    "\n",
    "# Defining the Predict Method\n",
    "  def predict(self,X):\n",
    "    X_with_bias = np.c_[self.X,-np.ones((len(self.X),1))]\n",
    "    return self.activationFunction(X_with_bias,self.weights)\n",
    "\n",
    "# Defining a method to calculate the loss\n",
    "  def total_loss(self):\n",
    "    total_loss = np.sum(self.error)\n",
    "    print(\"Toal loss\",total_loss)\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tqp-6mWLEe_g"
   },
   "outputs": [],
   "source": [
    "# A Method to separate the independent and Dependent features\n",
    "def prepare_data(df):\n",
    "    X=df.drop(\"y\",axis=1)\n",
    "    y=df['y']\n",
    "  \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "G6nJWuTIEwV5"
   },
   "outputs": [],
   "source": [
    "# Populating Data to implement the AND Logic gate\n",
    "AND ={\n",
    "    \n",
    "    \"x1\":[0,0,1,1],\n",
    "    \"x2\":[0,1,0,1],\n",
    "    \"y\":[0,0,0,1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(AND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Tkxu_BkNE-je"
   },
   "outputs": [],
   "source": [
    "X,y = prepare_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Perceptron & Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoM7wslBFDB3",
    "outputId": "d38dca36-8593-46fa-b8c6-5601ac67d699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights [-1.65836755e-06 -4.82264774e-05  1.39375260e-04]\n",
      "X with Bias  [[ 0.  0. -1.]\n",
      " [ 0.  1. -1.]\n",
      " [ 1.  0. -1.]\n",
      " [ 1.  1. -1.]]\n",
      "====================\n",
      "for epoch 0\n",
      "====================\n",
      "predicted values [0 0 0 0]\n",
      "Updated weights after epoch 10 [ 0.29999834  0.29995177 -0.29986062]\n",
      "====================\n",
      "for epoch 1\n",
      "====================\n",
      "predicted values [1 1 1 1]\n",
      "Updated weights after epoch 10 [-1.65836755e-06 -4.82264774e-05  6.00139375e-01]\n",
      "====================\n",
      "for epoch 2\n",
      "====================\n",
      "predicted values [0 0 0 0]\n",
      "Updated weights after epoch 10 [0.29999834 0.29995177 0.30013938]\n",
      "====================\n",
      "for epoch 3\n",
      "====================\n",
      "predicted values [0 0 0 1]\n",
      "Toal loss 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETA=0.3  # Learning Rate\n",
    "EPOCHS = 10 # Epochs\n",
    "\n",
    "model = Perceptron(eta=ETA, epochs=EPOCHS)\n",
    "model.fit(X,y)\n",
    "model.total_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Perceptron Algorithm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
